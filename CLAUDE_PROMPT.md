# ğŸ¤– Prompt para Claude - AnÃ¡lisis e ImplementaciÃ³n de Voz en PULSE-HUB

## ğŸ“‹ Contexto del Proyecto

Tu tarea es **analizar el proyecto de voz** ubicado en `agente-ia-conversacional-main/` e **implementarlo en PULSE-HUB**, una plataforma B2B desarrollada para **Ecos de Liderazgo** - un ecosistema humano-tecnolÃ³gico para la adopciÃ³n de IA Ã©tica y efectiva en empresas.

**IMPORTANTE**: El asistente de IA se implementarÃ¡ posteriormente con un MCP de OpenAI. Tu rol es analizar y adaptar las funcionalidades de voz existentes.

### ğŸ¯ Objetivo de la Tarea
Analizar las funcionalidades de voz del proyecto `agente-ia-conversacional-main/` e implementarlas en PULSE-HUB, respetando la arquitectura existente y adaptÃ¡ndolas a los tres pilares de la plataforma:

1. **ğŸ“ CapacitaciÃ³n IA** - FormaciÃ³n escalonada y especializada
2. **ğŸ“ˆ AdopciÃ³n Diaria** - Rituales y herramientas para uso cotidiano  
3. **âš¡ AutomatizaciÃ³n de Alto Impacto** - Procesos automatizados con ROI medible

### ğŸ—ï¸ Arquitectura del Sistema
- **Frontend**: Next.js 15 + TypeScript + Tailwind CSS
- **Backend**: Node.js + Express + TypeScript
- **Monorepo**: npm workspaces con packages compartidos
- **Design System**: Colores, tipografÃ­a y componentes estandarizados

---

## ğŸ™ï¸ AnÃ¡lisis del Proyecto de Voz

### ğŸ“ Proyecto a Analizar: `agente-ia-conversacional-main/`

Este proyecto contiene un sistema completo de conversaciÃ³n por voz que debes **analizar y adaptar** para PULSE-HUB:

#### ğŸ”§ Componentes de Voz Disponibles

**1. Reconocimiento de Voz en Tiempo Real**
```javascript
// ConfiguraciÃ³n optimizada para espaÃ±ol
recognition.lang = "es-ES";
recognition.continuous = true;
recognition.interimResults = false;
recognition.maxAlternatives = 1;
```

**2. SÃ­ntesis de Voz Natural**
```javascript
// Voz espaÃ±ola de alta calidad (Google/Microsoft)
utterance.rate = 0.9;    // Velocidad optimizada para claridad
utterance.pitch = 1.05;  // Tono cÃ¡lido y profesional
utterance.volume = 1.0;  // Volumen completo
```

**3. Filtros de Audio Profesionales**
```javascript
// Stream de audio con filtros avanzados
audio: {
  echoCancellation: true,      // Elimina eco del altavoz
  noiseSuppression: true,       // Reduce ruido ambiental
  autoGainControl: true,        // Normaliza volumen automÃ¡ticamente
  sampleRate: 48000,            // Calidad profesional (48kHz)
  channelCount: 1               // Mono optimizado para voz
}
```

**4. InterrupciÃ³n "Barge-in" Robusta**
```javascript
// DetecciÃ³n inmediata cuando usuario habla
if (isAgentSpeaking) {
  speechSynthesis.cancel();
  isAgentSpeaking = false;
  // Feedback visual de interrupciÃ³n
}
```

**5. Limpieza de Markdown para Voz**
```javascript
// FunciÃ³n que elimina caracteres de formato para sÃ­ntesis natural
function cleanTextForSpeech(text) {
  // Elimina **negrita**, *cursiva*, # encabezados, 1. listas, etc.
  // Mantiene formato visual en chat, limpia para voz
}
```

#### ğŸ§  Componentes de IA (Para AnÃ¡lisis)
- **OpenAI GPT-4o-mini** con function calling automÃ¡tico
- **Base de conocimiento en Coda** para consultas especializadas
- **Memoria conversacional** (Ãºltimos 10 mensajes)
- **Sistema de trazas** para anÃ¡lisis y debugging

**NOTA**: Estos componentes de IA se reemplazarÃ¡n posteriormente con el MCP de OpenAI. Tu tarea es analizar cÃ³mo se integran con las funcionalidades de voz.

---

## ğŸ¯ Instrucciones EspecÃ­ficas para Claude

### 1. **AnÃ¡lisis del Proyecto de Voz**

Tu primera tarea es **analizar completamente** el proyecto `agente-ia-conversacional-main/`:

**a) Examinar la Estructura:**
- Revisar todos los archivos del proyecto
- Identificar componentes de voz (reconocimiento, sÃ­ntesis, filtros)
- Analizar la integraciÃ³n con WebSocket y backend
- Documentar las dependencias y configuraciones

**b) Identificar Funcionalidades Clave:**
- Sistema de reconocimiento de voz en tiempo real
- SÃ­ntesis de voz natural en espaÃ±ol
- Filtros de audio profesionales
- InterrupciÃ³n "barge-in" robusta
- Limpieza de markdown para voz natural

**c) Analizar IntegraciÃ³n con IA:**
- CÃ³mo se comunica con OpenAI GPT-4o-mini
- Sistema de memoria conversacional
- Base de conocimiento en Coda
- Sistema de trazas y debugging

### 2. **AdaptaciÃ³n para PULSE-HUB**

Una vez analizado, adaptar las funcionalidades para PULSE-HUB:

**a) Adaptar Componentes de Voz:**
- Extraer y adaptar el cÃ³digo de voz de `agente-ia-conversacional-main/client/index.html`
- Implementar en la estructura de PULSE-HUB (`apps/web/src/`)
- Mantener el design system existente (colores, tipografÃ­a, componentes)
- Crear componentes React/TypeScript reutilizables

**b) Adaptar Backend:**
- Analizar `server/agent.ts` y `server/main.ts` del proyecto original
- Adaptar para la arquitectura de PULSE-HUB (Express + TypeScript)
- Mantener compatibilidad con el sistema de autenticaciÃ³n existente
- Preparar para integraciÃ³n futura con MCP de OpenAI

**c) Personalizar para PULSE-HUB:**
- Adaptar el contexto de "estrategias de IA" a los tres pilares de PULSE-HUB
- Preparar estructura para respuestas del asistente (que se implementarÃ¡ con MCP)
- Integrar con la base de conocimiento especÃ­fica de Ecos de Liderazgo
- Mantener compatibilidad con el sistema de diseÃ±o existente

### 3. **Estructura de Archivos Recomendada**

```
apps/web/src/
â”œâ”€â”€ features/
â”‚   â””â”€â”€ ai-chat/
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ ChatInterface.tsx      # Interfaz principal del chat del asistente
â”‚       â”‚   â”œâ”€â”€ VoiceConversation.tsx  # Nuevo Frontend de conversaciÃ³n por voz
â”‚       â”‚   â”œâ”€â”€ VoiceControls.tsx      # BotÃ³n de micrÃ³fono (barras) y controles
â”‚       â”‚   â”œâ”€â”€ MessageList.tsx        # Lista de mensajes del chat
â”‚       â”‚   â””â”€â”€ VoiceIndicator.tsx     # Indicadores de estado de voz
â”‚       â”œâ”€â”€ hooks/
â”‚       â”‚   â”œâ”€â”€ useVoiceRecognition.ts # Hook para reconocimiento de voz
â”‚       â”‚   â”œâ”€â”€ useVoiceSynthesis.ts   # Hook para sÃ­ntesis de voz
â”‚       â”‚   â”œâ”€â”€ useWebSocket.ts        # Hook para comunicaciÃ³n WebSocket
â”‚       â”‚   â””â”€â”€ useVoiceConversation.ts # Hook para manejar interfaz persistente
â”‚       â”œâ”€â”€ services/
â”‚       â”‚   â””â”€â”€ voiceService.ts        # Servicio de limpieza de texto para voz
â”‚       â””â”€â”€ types/
â”‚           â””â”€â”€ voice.types.ts         # Tipos TypeScript para voz

apps/api/src/
â”œâ”€â”€ features/
â”‚   â””â”€â”€ ai-chat/
â”‚       â”œâ”€â”€ voiceAgent.ts              # Agente conversacional adaptado
â”‚       â”œâ”€â”€ voiceRoutes.ts             # Rutas para chat con voz
â”‚       â””â”€â”€ voiceService.ts            # Servicio de procesamiento
```

**ENFOQUE**: 
- **VoiceConversation.tsx**: Nuevo Frontend que se abre dentro del chat
- **Interfaz persistente**: No se cierra automÃ¡ticamente, solo cuando el usuario lo decide
- **BotÃ³n de micrÃ³fono (barras)**: Indica que el agente estÃ¡ escuchando
- **Control total del usuario**: Sobre cuÃ¡ndo abrir/cerrar la interfaz de voz

### 4. **ConfiguraciÃ³n de Variables de Entorno**

```env
# WebSocket (para comunicaciÃ³n en tiempo real)
WEBSOCKET_PORT=3001

# OpenAI (Para integraciÃ³n futura con MCP)
# OPENAI_API_KEY=tu_openai_api_key_aqui
# OPENAI_MODEL=gpt-4o-mini
# OPENAI_MAX_TOKENS=1000

# Coda (Para base de conocimiento - opcional)
# CODA_API_KEY=tu_coda_api_key_aqui
# CODA_DOC_ID=tu_doc_id_aqui
# CODA_TABLE_ID=tu_table_id_aqui
```

**NOTA**: Las variables de OpenAI y Coda estÃ¡n comentadas ya que se implementarÃ¡n posteriormente con el MCP.

### 5. **PreparaciÃ³n para IntegraciÃ³n con MCP**

**Estructura Preparada para MCP:**
```typescript
// Interfaces preparadas para integraciÃ³n con MCP de OpenAI
interface VoiceMessage {
  type: 'user_message' | 'assistant_message';
  text: string;
  timestamp: Date;
  sessionId: string;
}

interface VoiceResponse {
  text: string;
  shouldSpeak: boolean;
  metadata?: {
    confidence?: number;
    intent?: string;
    context?: string;
  };
}

// Estado de la interfaz de conversaciÃ³n por voz
interface VoiceConversationState {
  isOpen: boolean;           // Si la interfaz estÃ¡ abierta
  isListening: boolean;      // Si el agente estÃ¡ escuchando
  isSpeaking: boolean;       // Si el agente estÃ¡ hablando
  messages: VoiceMessage[];  // Historial de mensajes
}

// Servicio preparado para MCP
class VoiceService {
  async processMessage(message: string): Promise<VoiceResponse> {
    // AquÃ­ se integrarÃ¡ con el MCP de OpenAI
    // Por ahora, estructura preparada
  }
}
```

**Contexto Preparado para PULSE-HUB:**
- Estructura de respuestas enfocada en los tres pilares
- Interfaces para casos de uso empresariales especÃ­ficos
- Referencias a la metodologÃ­a "Ecos de Liderazgo"
- PreparaciÃ³n para mÃ©tricas y KPIs de adopciÃ³n

### 6. **IntegraciÃ³n con Design System**

**Colores del Sistema:**
```css
/* Usar los colores establecidos de PULSE-HUB */
--primary-600: #1F5AF6   /* Botones principales */
--primary-100: #E8EFFD   /* Fondos suaves */
--accent-orange: #FF7A45 /* CTAs clave */
--neutral-900: #0A1633   /* Texto principal */
```

**Componentes Reutilizables:**
- Usar `Button` component existente con variantes
- Integrar con `Card` component para el chat
- Mantener consistencia con `Navbar` y `Footer`

### 7. **Funcionalidades de Voz a Implementar**

**OBJETIVO ESPECÃFICO**: Implementar funcionalidades de voz **Ãºnicamente dentro del asistente de IA**, no en otras partes de la pÃ¡gina.

**a) Interfaz de ConversaciÃ³n por Voz:**
- **Nuevo Frontend que se abre dentro del chat** del asistente
- **BotÃ³n de micrÃ³fono (barras)** que indica que el agente estÃ¡ escuchando
- **Interfaz persistente** que permanece abierta hasta que el usuario la cierre
- **No se cierra automÃ¡ticamente** - control total del usuario

**b) Flujo de ConversaciÃ³n:**
- Usuario abre la interfaz de conversaciÃ³n por voz
- Presiona el botÃ³n de micrÃ³fono (barras) para activar escucha
- El agente escucha y procesa el mensaje del usuario
- El agente responde con voz natural en espaÃ±ol
- La interfaz permanece abierta para continuar la conversaciÃ³n
- Usuario puede cerrar la interfaz cuando decida

**c) IntegraciÃ³n con MCP de OpenAI:**
- Las respuestas del asistente (via MCP) se reproducen con voz
- El usuario puede interactuar por voz con el asistente
- Mantener funcionalidad de chat por texto como alternativa

**NOTA**: La voz se implementa SOLO en el chat del asistente, no en otras secciones de la pÃ¡gina.

### 8. **Consideraciones TÃ©cnicas**

**Compatibilidad de Navegadores:**
- Chrome/Edge: Soporte completo
- Firefox: Soporte bÃ¡sico
- Safari: Limitaciones conocidas
- Mobile: Funcionalidad reducida

**Optimizaciones de Rendimiento:**
- Lazy loading del mÃ³dulo de voz
- CompresiÃ³n de audio streams
- CachÃ© de respuestas frecuentes
- Debounce en reconocimiento de voz

**Accesibilidad:**
- Indicadores visuales claros
- NavegaciÃ³n por teclado
- TranscripciÃ³n de conversaciones
- Controles de volumen y velocidad

### 9. **Testing y ValidaciÃ³n**

**Casos de Prueba Esenciales:**
1. **SelecciÃ³n de Voz**: Verificar que se selecciona voz espaÃ±ola de calidad
2. **Filtros de Audio**: Probar con ruido ambiental
3. **Barge-in**: Interrumpir al agente mientras habla
4. **Limpieza de Markdown**: Verificar que no pronuncia asteriscos
5. **IntegraciÃ³n WebSocket**: ComunicaciÃ³n en tiempo real
6. **Responsive Design**: Funcionalidad en mobile
7. **PreparaciÃ³n para MCP**: Estructura lista para integraciÃ³n futura

**MÃ©tricas de Calidad:**
- Latencia de respuesta < 2 segundos
- PrecisiÃ³n de reconocimiento > 90%
- Tasa de interrupciones exitosas > 95%
- SatisfacciÃ³n del usuario > 8/10

---

## ğŸš€ Comandos de ImplementaciÃ³n

### Paso 1: Analizar Proyecto Original
```bash
# Examinar estructura del proyecto de voz
cd agente-ia-conversacional-main/
ls -la
cat README.md
cat package.json
```

### Paso 2: Configurar Dependencias
```bash
# En apps/web
npm install ws @types/ws

# En apps/api  
npm install ws @types/ws
```

### Paso 3: Crear Estructura Base
```bash
# Crear directorios
mkdir -p apps/web/src/features/ai-chat/{components,hooks,services,types}
mkdir -p apps/api/src/features/ai-chat
```

### Paso 4: Analizar y Adaptar Componentes de Voz
- Analizar cÃ³digo de `agente-ia-conversacional-main/client/index.html`
- Extraer funcionalidades de voz (reconocimiento, sÃ­ntesis, filtros)
- Crear **VoiceConversation.tsx** - nuevo Frontend que se abre dentro del chat
- Implementar **interfaz persistente** que no se cierra automÃ¡ticamente
- Adaptar **botÃ³n de micrÃ³fono (barras)** para indicar escucha del agente
- Integrar con design system de PULSE-HUB
- **ENFOQUE**: Interfaz de voz persistente dentro del chat del asistente

### Paso 5: Adaptar Backend
- Analizar `server/agent.ts` y `server/main.ts`
- Adaptar para arquitectura de PULSE-HUB
- Configurar WebSocket server
- Preparar estructura para MCP de OpenAI

### Paso 6: Testing y ValidaciÃ³n
- Probar funcionalidades de voz
- Validar integraciÃ³n con PULSE-HUB
- Verificar preparaciÃ³n para MCP
- Documentar implementaciÃ³n

---

## ğŸ“š Recursos de Referencia

### Archivos Clave del Proyecto Base:
- `agente-ia-conversacional-main/client/index.html` - Interfaz completa de voz
- `agente-ia-conversacional-main/server/agent.ts` - LÃ³gica del agente
- `agente-ia-conversacional-main/server/main.ts` - Servidor WebSocket
- `agente-ia-conversacional-main/MEJORAS_VOZ_IMPLEMENTADAS.md` - DocumentaciÃ³n tÃ©cnica

### DocumentaciÃ³n PULSE-HUB:
- `README.md` - Arquitectura y estructura del proyecto
- `docs/design/DESIGN-SYSTEM-PROMPT.md` - Sistema de diseÃ±o
- `docs/product/PRD-PULSE-HUB.md` - Requisitos del producto

---

## ğŸ¯ Objetivo Final

Crear un sistema de voz integrado **Ãºnicamente en el chat del asistente de IA** de PULSE-HUB que:

âœ… **Analice completamente** el proyecto `agente-ia-conversacional-main/`
âœ… **Adapte las funcionalidades de voz** a la arquitectura de PULSE-HUB
âœ… **Implemente voz SOLO en el chat del asistente**, no en otras partes de la pÃ¡gina
âœ… **Mantenga la identidad visual** y experiencia de usuario de la plataforma
âœ… **Proporcione conversaciÃ³n natural** en espaÃ±ol con calidad profesional  
âœ… **Se integre perfectamente** con la arquitectura existente
âœ… **Prepare la estructura** para integraciÃ³n futura con MCP de OpenAI
âœ… **Sea accesible y responsive** en todos los dispositivos
âœ… **Mantenga altos estÃ¡ndares** de calidad y rendimiento

**Resultado esperado**: Un chat de asistente con un nuevo Frontend de conversaciÃ³n por voz que:
- Se abre dentro del chat del asistente
- Permanece abierto hasta que el usuario decida cerrarlo
- Incluye un botÃ³n de micrÃ³fono (barras) que indica cuando el agente estÃ¡ escuchando
- Permite conversaciÃ³n continua por voz sin cerrarse automÃ¡ticamente
- Mantiene el control total del usuario sobre la interfaz

---

*Este prompt estÃ¡ diseÃ±ado para guiar el anÃ¡lisis y adaptaciÃ³n del proyecto de voz, manteniendo la coherencia con PULSE-HUB y preparando la estructura para la integraciÃ³n futura del asistente de IA mediante MCP de OpenAI.*