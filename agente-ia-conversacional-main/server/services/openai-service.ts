// server/services/openai-service.ts
import OpenAI from 'openai';
import type { ChatCompletionMessageParam, ChatCompletionTool } from 'openai/resources/chat/completions';
import { searchInCoda } from '../tools/coda.js';
import type { ConversationMessage, OpenAIConfig } from '../types/conversation.js';

/**
 * System prompt optimizado para el asistente de estrategias de IA
 */
const SYSTEM_PROMPT = `Eres un asistente experto en estrategias de adopci√≥n de inteligencia artificial para empresas. Tu conocimiento proviene de una base de datos especializada que contiene informaci√≥n sobre:

- Pilares de implementaci√≥n de IA (IA para Todos, IA en el D√≠a a D√≠a, Automatizaci√≥n de Alto Impacto)
- Estrategias de capacitaci√≥n escalonada por niveles (directivos, mandos medios, operativos)
- Casos de uso empresariales y mejores pr√°cticas
- M√©tricas y KPIs de √©xito para proyectos de IA
- Roadmaps y fases de implementaci√≥n
- An√°lisis de riesgo y mitigaci√≥n

INSTRUCCIONES IMPORTANTES:
1. SIEMPRE basa tus respuestas en la informaci√≥n de la base de conocimiento
2. Si necesitas informaci√≥n espec√≠fica, usa la funci√≥n searchInCoda para buscarla
3. S√© conciso pero completo (m√°ximo 200-250 palabras por respuesta)
4. Usa formato conversacional y natural en espa√±ol
5. Si no encuentras informaci√≥n espec√≠fica en la base, recon√≥celo honestamente
6. Ofrece seguimiento preguntando si necesitan m√°s detalles o aclaraciones
7. Estructura tus respuestas con:
   - Respuesta directa a la pregunta
   - Ejemplos concretos cuando sea relevante
   - Pregunta de seguimiento para profundizar

Tu objetivo es ayudar a empresas a implementar IA de manera exitosa y estrat√©gica.`;

/**
 * Definici√≥n de las tools (function calling) disponibles para el asistente
 */
const TOOLS: ChatCompletionTool[] = [
  {
    type: 'function',
    function: {
      name: 'searchInCoda',
      description: 'Busca informaci√≥n sobre estrategias de adopci√≥n de IA, capacitaci√≥n, automatizaci√≥n y mejores pr√°cticas en la base de conocimiento. Usa esta funci√≥n cuando necesites informaci√≥n espec√≠fica para responder una pregunta del usuario.',
      parameters: {
        type: 'object',
        properties: {
          query: {
            type: 'string',
            description: 'La pregunta o tema a buscar en la base de conocimiento. Reformula la pregunta del usuario para maximizar la relevancia de los resultados. Ejemplos: "capacitaci√≥n escalonada IA", "m√©tricas √©xito implementaci√≥n IA", "pilares adopci√≥n inteligencia artificial"'
          }
        },
        required: ['query']
      }
    }
  }
];

/**
 * Servicio de OpenAI para gestionar conversaciones inteligentes
 * con function calling y memoria conversacional
 */
export class OpenAIService {
  private client: OpenAI;
  private config: OpenAIConfig;
  private conversationHistory: Map<string, ConversationMessage[]>;
  private maxHistoryLength: number = 10; // √öltimos 10 mensajes

  constructor(config: OpenAIConfig) {
    this.config = config;
    this.client = new OpenAI({
      apiKey: config.apiKey,
    });
    this.conversationHistory = new Map();

    console.log('‚úÖ OpenAI Service inicializado con modelo:', config.model);
  }

  /**
   * Procesa un mensaje del usuario y genera una respuesta inteligente
   * @param userMessage Mensaje del usuario
   * @param sessionId ID de la sesi√≥n para mantener contexto
   * @returns Respuesta generada por el asistente
   */
  async processMessage(userMessage: string, sessionId: string = 'default'): Promise<string> {
    try {
      // Obtener o inicializar historial de conversaci√≥n
      const history = this.getConversationHistory(sessionId);

      // Agregar mensaje del usuario al historial
      const userMsg: ConversationMessage = {
        role: 'user',
        content: userMessage,
        timestamp: Date.now()
      };
      history.push(userMsg);

      // Preparar mensajes para OpenAI
      const messages: ChatCompletionMessageParam[] = [
        { role: 'system', content: SYSTEM_PROMPT },
        ...history.map(msg => ({
          role: msg.role,
          content: msg.content
        }))
      ];

      // Llamar a OpenAI con function calling habilitado
      const response = await this.client.chat.completions.create({
        model: this.config.model,
        messages: messages,
        tools: TOOLS,
        tool_choice: 'auto', // OpenAI decide si necesita usar tools
        max_tokens: this.config.maxTokens,
        temperature: this.config.temperature ?? 0.7,
      });

      const choice = response.choices[0];

      // Si OpenAI quiere ejecutar una funci√≥n
      if (choice.finish_reason === 'tool_calls' && choice.message.tool_calls) {
        return await this.handleToolCalls(choice.message, messages, sessionId);
      }

      // Respuesta directa sin tool calls
      const assistantResponse = choice.message.content || 'Lo siento, no pude generar una respuesta.';

      // Agregar respuesta del asistente al historial
      history.push({
        role: 'assistant',
        content: assistantResponse,
        timestamp: Date.now()
      });

      // Guardar historial actualizado
      this.updateConversationHistory(sessionId, history);

      return assistantResponse;

    } catch (error) {
      console.error('‚ùå Error en OpenAI Service:', error);
      throw new Error(`Error procesando mensaje: ${error instanceof Error ? error.message : String(error)}`);
    }
  }

  /**
   * Maneja las llamadas a funciones (tools) solicitadas por OpenAI
   */
  private async handleToolCalls(
    assistantMessage: any,
    messages: ChatCompletionMessageParam[],
    sessionId: string
  ): Promise<string> {
    // Agregar mensaje del asistente con tool calls al contexto
    messages.push(assistantMessage);

    // Ejecutar cada tool call
    for (const toolCall of assistantMessage.tool_calls) {
      const functionName = toolCall.function.name;
      const functionArgs = JSON.parse(toolCall.function.arguments);

      console.log(`üîß OpenAI solicit√≥ tool: ${functionName} con args:`, functionArgs);

      let functionResponse: string;

      // Ejecutar la funci√≥n correspondiente
      if (functionName === 'searchInCoda') {
        const searchResult = await searchInCoda(functionArgs.query);
        functionResponse = searchResult || 'No se encontr√≥ informaci√≥n relevante en la base de conocimiento.';
        console.log(`üìä Resultado de b√∫squeda en Coda: ${searchResult ? 'Encontrado' : 'No encontrado'} (${searchResult?.length || 0} chars)`);
      } else {
        functionResponse = `Funci√≥n ${functionName} no implementada.`;
      }

      // Agregar resultado de la funci√≥n al contexto
      messages.push({
        role: 'tool',
        content: functionResponse,
        tool_call_id: toolCall.id
      });
    }

    // Llamar nuevamente a OpenAI con los resultados de las funciones
    const secondResponse = await this.client.chat.completions.create({
      model: this.config.model,
      messages: messages,
      max_tokens: this.config.maxTokens,
      temperature: this.config.temperature ?? 0.7,
    });

    const finalResponse = secondResponse.choices[0].message.content ||
      'Lo siento, no pude generar una respuesta con la informaci√≥n encontrada.';

    // Actualizar historial con la respuesta final
    const history = this.getConversationHistory(sessionId);
    history.push({
      role: 'assistant',
      content: finalResponse,
      timestamp: Date.now()
    });
    this.updateConversationHistory(sessionId, history);

    return finalResponse;
  }

  /**
   * Obtiene el historial de conversaci√≥n para una sesi√≥n
   */
  private getConversationHistory(sessionId: string): ConversationMessage[] {
    if (!this.conversationHistory.has(sessionId)) {
      this.conversationHistory.set(sessionId, []);
    }
    return this.conversationHistory.get(sessionId)!;
  }

  /**
   * Actualiza el historial y limita su tama√±o
   */
  private updateConversationHistory(sessionId: string, history: ConversationMessage[]): void {
    // Mantener solo los √∫ltimos N mensajes para no exceder l√≠mites de contexto
    if (history.length > this.maxHistoryLength) {
      history.splice(0, history.length - this.maxHistoryLength);
    }
    this.conversationHistory.set(sessionId, history);
  }

  /**
   * Limpia el historial de una sesi√≥n espec√≠fica
   */
  clearHistory(sessionId: string): void {
    this.conversationHistory.delete(sessionId);
    console.log(`üóëÔ∏è Historial limpiado para sesi√≥n: ${sessionId}`);
  }

  /**
   * Limpia todo el historial
   */
  clearAllHistory(): void {
    this.conversationHistory.clear();
    console.log('üóëÔ∏è Todo el historial de conversaciones limpiado');
  }
}

/**
 * Crea una instancia del servicio OpenAI desde variables de entorno
 */
export function createOpenAIService(): OpenAIService {
  const apiKey = process.env.OPENAI_API_KEY;
  const model = process.env.OPENAI_MODEL || 'gpt-4o-mini';
  const maxTokens = parseInt(process.env.OPENAI_MAX_TOKENS || '1000', 10);

  if (!apiKey) {
    throw new Error('OPENAI_API_KEY no est√° configurada en las variables de entorno');
  }

  const config: OpenAIConfig = {
    apiKey,
    model,
    maxTokens,
    temperature: 0.7
  };

  return new OpenAIService(config);
}
