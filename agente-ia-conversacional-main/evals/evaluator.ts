// evals/evaluator.ts
import "dotenv/config";
import { RealtimeAgent } from '../server/agent.js';
import { AccuracyEvaluator } from './metrics/accuracy.js';
import { ToneEvaluator } from './metrics/tone.js';
import { LatencyEvaluator } from './metrics/latency.js';
import fs from 'fs/promises';
import path from 'path';

export interface EvalResult {
  metric: string;
  score: number;
  maxScore: number;
  percentage: number;
  details: any;
  timestamp: string;
}

export interface EvalReport {
  overall: {
    score: number;
    maxScore: number;
    percentage: number;
  };
  metrics: EvalResult[];
  summary: string;
  timestamp: string;
}

export class EvalSystem {
  private agent: RealtimeAgent;
  private accuracyEvaluator: AccuracyEvaluator;
  private toneEvaluator: ToneEvaluator;
  private latencyEvaluator: LatencyEvaluator;

  constructor() {
    this.agent = new RealtimeAgent();
    this.accuracyEvaluator = new AccuracyEvaluator();
    this.toneEvaluator = new ToneEvaluator();
    this.latencyEvaluator = new LatencyEvaluator();
  }

  private checkApiKey(): void {
    if (!process.env.OPENWEATHER_API_KEY) {
      console.error('‚ùå Error: OPENWEATHER_API_KEY no est√° configurada');
      console.error('üí° Las evaluaciones de exactitud requieren esta API key.');
      console.error('üí° Configura el secret en GitHub o el archivo .env localmente.');
      throw new Error('OPENWEATHER_API_KEY no configurada');
    }
    console.log('‚úÖ API key cargada correctamente');
  }

  async runAllEvals(): Promise<EvalReport> {
    console.log('üß™ Iniciando evaluaciones autom√°ticas...\n');

    // Verificar API key para evaluaciones de exactitud
    this.checkApiKey();

    const results: EvalResult[] = [];

    // 1. Evaluaci√≥n de Exactitud
    console.log('üìä Evaluando exactitud...');
    const accuracyResult = await this.accuracyEvaluator.evaluate(this.agent);
    results.push(accuracyResult);
    console.log(`‚úÖ Exactitud: ${accuracyResult.percentage.toFixed(1)}%\n`);

    // 2. Evaluaci√≥n de Tono
    console.log('üé≠ Evaluando tono conversacional...');
    const toneResult = await this.toneEvaluator.evaluate(this.agent);
    results.push(toneResult);
    console.log(`‚úÖ Tono: ${toneResult.percentage.toFixed(1)}%\n`);

    // 3. Evaluaci√≥n de Latencia
    console.log('‚ö° Evaluando latencia...');
    const latencyResult = await this.latencyEvaluator.evaluate(this.agent);
    results.push(latencyResult);
    console.log(`‚úÖ Latencia: ${latencyResult.percentage.toFixed(1)}%\n`);

    // Calcular puntuaci√≥n general
    const totalScore = results.reduce((sum, result) => sum + result.score, 0);
    const maxScore = results.reduce((sum, result) => sum + result.maxScore, 0);
    const overallPercentage = (totalScore / maxScore) * 100;

    const report: EvalReport = {
      overall: {
        score: totalScore,
        maxScore: maxScore,
        percentage: overallPercentage
      },
      metrics: results,
      summary: this.generateSummary(results, overallPercentage),
      timestamp: new Date().toISOString()
    };

    // Guardar reporte
    await this.saveReport(report);

    console.log('üìã RESUMEN FINAL:');
    console.log(`üéØ Puntuaci√≥n General: ${overallPercentage.toFixed(1)}%`);
    console.log(`üìä Total: ${totalScore}/${maxScore} puntos`);
    console.log(`üìù ${report.summary}\n`);

    return report;
  }

  private generateSummary(results: EvalResult[], overallPercentage: number): string {
    const passedTests = results.filter(r => r.percentage >= 80).length;
    const totalTests = results.length;

    if (overallPercentage >= 90) {
      return `Excelente rendimiento. ${passedTests}/${totalTests} m√©tricas superaron el 80%. El agente est√° listo para producci√≥n.`;
    } else if (overallPercentage >= 75) {
      return `Buen rendimiento. ${passedTests}/${totalTests} m√©tricas superaron el 80%. Se recomiendan mejoras menores.`;
    } else if (overallPercentage >= 60) {
      return `Rendimiento aceptable. ${passedTests}/${totalTests} m√©tricas superaron el 80%. Se requieren mejoras importantes.`;
    } else {
      return `Rendimiento insuficiente. Solo ${passedTests}/${totalTests} m√©tricas superaron el 80%. Se requiere revisi√≥n completa.`;
    }
  }

  private async saveReport(report: EvalReport): Promise<void> {
    const reportsDir = path.join(process.cwd(), 'evals', 'reports');
    
    try {
      await fs.mkdir(reportsDir, { recursive: true });
      
      const filename = `report-${new Date().toISOString().split('T')[0]}.json`;
      const filepath = path.join(reportsDir, filename);
      
      await fs.writeFile(filepath, JSON.stringify(report, null, 2));
      await fs.writeFile(path.join(reportsDir, 'latest-report.json'), JSON.stringify(report, null, 2));
      
      console.log(`üíæ Reporte guardado: ${filename}`);
    } catch (error) {
      console.error('‚ùå Error guardando reporte:', error);
    }
  }

  async runSpecificEval(metric: 'accuracy' | 'tone' | 'latency'): Promise<EvalResult> {
    console.log(`üß™ Ejecutando evaluaci√≥n: ${metric}\n`);

    switch (metric) {
      case 'accuracy':
        // Solo accuracy requiere API key
        this.checkApiKey();
        return await this.accuracyEvaluator.evaluate(this.agent);
      case 'tone':
        return await this.toneEvaluator.evaluate(this.agent);
      case 'latency':
        return await this.latencyEvaluator.evaluate(this.agent);
      default:
        throw new Error(`M√©trica no soportada: ${metric}`);
    }
  }
}
