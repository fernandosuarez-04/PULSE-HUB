# ğŸ§ª GuÃ­a de Evaluaciones AutomÃ¡ticas (Evals)

## ğŸ“‹ Tabla de Contenidos
- [Comandos Disponibles](#comandos-disponibles)
- [Flujo en GitHub Actions](#flujo-en-github-actions)
- [ConfiguraciÃ³n de Secrets](#configuraciÃ³n-de-secrets)
- [Resultados y Reportes](#resultados-y-reportes)

## ğŸš€ Comandos Disponibles

### Ejecutar Todas las Evaluaciones
```bash
npm run evals
# Requiere: OPENWEATHER_API_KEY configurada
# Ejecuta: Exactitud + Tono + Latencia
# Resultado: PuntuaciÃ³n general + reporte completo
```

### Evaluaciones Individuales

#### ğŸ¯ Exactitud (Accuracy)
```bash
npm run evals:accuracy
# Requiere: OPENWEATHER_API_KEY
# EvalÃºa: PrecisiÃ³n en respuestas de clima
# Tiempo: ~30 segundos
```

#### ğŸ­ Tono (Tone)
```bash
npm run evals:tone
# Requiere: Nada (funciona siempre)
# EvalÃºa: Amabilidad, coherencia, estilo
# Tiempo: ~20 segundos
```

#### âš¡ Latencia (Latency)
```bash
npm run evals:latency
# Requiere: Nada (funciona siempre)
# EvalÃºa: Tiempos de respuesta, consistencia
# Tiempo: ~40 segundos
```

## ğŸ”„ Flujo en GitHub Actions

### Â¿CuÃ¡ndo se ejecuta automÃ¡ticamente?

#### 1ï¸âƒ£ Al hacer PUSH a main o develop
```bash
git add .
git commit -m "feat: nueva funcionalidad"
git push origin main
# â† AquÃ­ se disparan las evaluaciones automÃ¡ticamente
```

#### 2ï¸âƒ£ Al crear o actualizar un Pull Request
```bash
git checkout -b feature/mi-feature
git add .
git commit -m "feat: implementar X"
git push origin feature/mi-feature
# Al crear el PR en GitHub:
# - âœ… Se ejecutan las evaluaciones
# - ğŸ’¬ Se comenta en el PR con resultados
# - âš ï¸ Si puntuaciÃ³n < 75%, se marca como warning
```

### ğŸ¯ Â¿QuÃ© archivos disparan las evaluaciones?

**SÃ ejecuta evaluaciones:**
- Cambios en `server/**` (cÃ³digo del agente)
- Cambios en `evals/**` (cÃ³digo de evaluaciones)
- Cambios en `package.json`
- Cambios en `tsconfig.json`

**NO ejecuta evaluaciones:**
- Cambios en `README.md`
- Cambios en `docs/`
- Cambios en `client/`

### ğŸ“Š Flujo del Workflow

```
1. ğŸ“¥ Checkout cÃ³digo
2. ğŸ“¦ Instalar Node.js 20
3. ğŸ“¦ Instalar dependencias (npm ci)
4. ğŸ”§ Compilar TypeScript
5. ğŸ­ Ejecutar evaluaciones de tono âœ… (siempre)
6. âš¡ Ejecutar evaluaciones de latencia âœ… (siempre)
7. ğŸ§ª Ejecutar evaluaciones de exactitud âš ï¸ (solo si hay API key)
8. ğŸ“Š Generar reporte completo âš ï¸ (solo si hay API key)
9. ğŸ“‹ Subir reporte como artifact
10. ğŸ’¬ Comentar en PR (si es PR)
```

## ğŸ” ConfiguraciÃ³n de Secrets

### Â¿Por quÃ© necesito configurar un Secret?

Las evaluaciones de **exactitud** necesitan conectarse a la API de OpenWeather para obtener datos reales de clima. Sin este secret:
- âœ… Evaluaciones de **tono** funcionan
- âœ… Evaluaciones de **latencia** funcionan
- âŒ Evaluaciones de **exactitud** se omiten
- âš ï¸ Reporte completo se omite

### CÃ³mo configurar el Secret en GitHub

**OpciÃ³n 1: Enlace directo**
```
https://github.com/nocode-ecosdeliderazgo/agente-ia-conversacional/settings/secrets/actions
```

**OpciÃ³n 2: Paso a paso**
1. Ve a tu repositorio en GitHub
2. Click en **Settings** (âš™ï¸)
3. En el menÃº izquierdo: **Secrets and variables** â†’ **Actions**
4. Click **New repository secret**
5. Nombre: `OPENWEATHER_API_KEY`
6. Valor: `76804eeaba5d02d088c60b73c847e528`
7. Click **Add secret**

### Verificar que funciona

DespuÃ©s de configurar el secret:
1. Haz un commit pequeÃ±o: `git commit --allow-empty -m "test: verificar evals"`
2. Push: `git push origin main`
3. Ve a la pestaÃ±a **Actions** en GitHub
4. VerÃ¡s el workflow ejecutÃ¡ndose
5. Debe mostrar **todas las evaluaciones** (incluida exactitud)

## ğŸ“Š Resultados y Reportes

### DÃ³nde ver los resultados

#### En Local
```bash
npm run evals
# Resultados en consola + archivo guardado en:
# evals/reports/latest-report.json
# evals/reports/report-2025-10-08.json
```

#### En GitHub Actions
1. Ve a tu repositorio en GitHub
2. Click en **Actions** (pestaÃ±a superior)
3. Click en la ejecuciÃ³n del workflow
4. Expande los pasos para ver logs detallados
5. Descarga el artifact `evals-report` para ver el JSON completo

#### En Pull Requests
El bot comenta automÃ¡ticamente con un resumen:
```markdown
## ğŸ§ª Resultados de Evaluaciones AutomÃ¡ticas

### ğŸ“Š PuntuaciÃ³n General: **88.1%** (282/320)

### ğŸ“ˆ MÃ©tricas Detalladas:
- ğŸŸ¢ **accuracy**: 86.0%
- ğŸŸ¢ **tone**: 80.0%
- ğŸŸ¢ **latency**: 100.0%

### ğŸ“ Resumen:
Buen rendimiento. 3/3 mÃ©tricas superaron el 80%.
Se recomiendan mejoras menores.

âœ… **Excelente**: La puntuaciÃ³n general es satisfactoria.
```

### InterpretaciÃ³n de Resultados

#### PuntuaciÃ³n General
- **90-100%** ğŸŸ¢ Excelente - Listo para producciÃ³n
- **75-89%** ğŸŸ¡ Bueno - Mejoras menores recomendadas
- **60-74%** ğŸŸ  Aceptable - Mejoras importantes requeridas
- **0-59%** ğŸ”´ Insuficiente - Requiere revisiÃ³n completa

#### Por MÃ©trica
- **Exactitud** (Accuracy): Â¿Responde correctamente?
- **Tono** (Tone): Â¿Es amigable y coherente?
- **Latencia** (Latency): Â¿Responde rÃ¡pidamente?

## ğŸ› ï¸ Troubleshooting

### Error: "OPENWEATHER_API_KEY no estÃ¡ configurada"

**En Local:**
```bash
# Verifica que existe el archivo .env
cat .env
# Debe contener:

```

**En GitHub:**
- Verifica que configuraste el secret correctamente
- El nombre debe ser exactamente: `OPENWEATHER_API_KEY`
- Revisa en Settings â†’ Secrets and variables â†’ Actions

### El workflow no se ejecuta

**Posibles causas:**
1. Los archivos modificados no estÃ¡n en la lista de paths (ej: solo modificaste README.md)
2. El workflow estÃ¡ deshabilitado en Settings â†’ Actions
3. El branch no es `main` ni `develop`

**SoluciÃ³n:**
```bash
# Forzar ejecuciÃ³n con commit vacÃ­o
git commit --allow-empty -m "test: trigger evals"
git push origin main
```

### Evaluaciones pasan en local pero fallan en GitHub

**Posibles causas:**
1. API key no configurada en GitHub
2. Diferencias de entorno (Node.js version, dependencias)
3. Tests no determinÃ­sticos

**SoluciÃ³n:**
```bash
# Ejecutar build local para simular CI
npm ci  # Instala dependencias limpias
npm run build
npm run evals
```

## ğŸ“ˆ Mejores PrÃ¡cticas

### Antes de hacer commit
```bash
# Ejecuta las evaluaciones localmente
npm run evals

# Si todo pasa, haz commit
git add .
git commit -m "feat: tu mensaje"
git push
```

### En Pull Requests
1. Espera a que pasen las evaluaciones antes de pedir review
2. Si falla alguna mÃ©trica < 80%, investiga por quÃ©
3. Usa los reportes para identificar quÃ© mejorar

### Monitoreo continuo
- Revisa los trends de puntuaciÃ³n en cada PR
- Si la puntuaciÃ³n baja consistentemente, es seÃ±al de regresiÃ³n
- MantÃ©n la puntuaciÃ³n general > 85%

## ğŸ¯ PrÃ³ximos Pasos

1. âœ… Configurar `OPENWEATHER_API_KEY` en GitHub Secrets
2. âœ… Hacer un commit de prueba para verificar el workflow
3. âœ… Revisar el comentario automÃ¡tico en PRs
4. ğŸ”„ Iterar mejorando las mÃ©tricas que estÃ©n < 90%
5. ğŸ“Š Monitorear trends de calidad en cada release
